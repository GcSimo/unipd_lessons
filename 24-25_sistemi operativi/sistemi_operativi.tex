\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc} % standard unicode
\usepackage[italian]{babel} % corretta sillabazione in italiano
\usepackage{geometry} % per impostare margini e layout pagina
\usepackage{amssymb} % per l'ambiente matematico
\usepackage{amsmath} % per l'ambiente matematico
\usepackage{enumitem} % per elenchi puntati
\usepackage{multirow} % per celle che si espandono su più righe
\usepackage{tabularx} % per tabelle con larghezza flessibile
\usepackage{booktabs} % per linee orizzontali tabelle
\usepackage{hyperref} % per collegamenti
\usepackage{graphicx} % per immagini
\usepackage{dirtytalk} % per le ""
\usepackage{forest} % per albero
\usepackage{listings} % per codice
\usepackage{xcolor} % per colori nel codice

% definizione colori per codice
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% definizione stile codice
\lstdefinestyle{mystyle}{
	language=C++,
	morekeywords={constexpr,string,C_style_cast,noexcept,alignof,std,wait,signal,acquire,release},
	emph={int,char,double,float,unsigned,string,vector,initializer_list,semaphore},
	backgroundcolor=\color{backcolour},    % sfondo
	commentstyle=\color{codegreen},        % commenti
	keywordstyle=\color{magenta},          % keywords
	identifierstyle=\color{blue},          % variabili
	stringstyle=\color{codepurple},        % stringhe
	directivestyle={\color{purple}},       % direttive
	emphstyle={\color{magenta}},           % tipi
	numberstyle=\tiny\color{codegray},     % numeri
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,
	breaklines=true,
	captionpos=b,
	keepspaces=true,
	numbers=left,
	numbersep=5pt,
	showspaces=false,
	showstringspaces=false,
	showtabs=false,
	tabsize=4
}

% utilizzo stile codice
\lstset{style=mystyle}
\lstset{literate={~} {{\raisebox{0.4ex}{\texttildelow}}}{1}}

% per margini
\geometry{a4paper,left=25mm, right=25mm, bottom=25mm, top=30mm}

% per centrare testo nelle tabelleX
\renewcommand\tabularxcolumn[1]{m{#1}}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\newcolumntype{R}{>{\raggedleft\arraybackslash}X}

% per elenchi puntati
\setlist[itemize]{label=-, partopsep=0pt, topsep=3pt, itemsep=0pt}

% percorso immagini
\graphicspath{ {./immagini/} }

% titolo sottotitolo e autori
\title{Sistemi Operativi}
\author{Giacomo Simonetto e Diego Chiesurin}
\date{Secondo Semestre 2024-25}

\begin{document}
\maketitle
\begin{abstract}
	Appunti del corso di Sistemi Operativi della facoltà di Ingegneria Informatica dell'Università di Padova.
\end{abstract}

\newpage

\tableofcontents

\newpage

% ___________________________________________________________________________________________________________________________________________________
% /////////////////////////////////////////////////////////////////////////|\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
% -------------------------------------------------------- INTRODUZIONE AI SISTEMI OPERATIVI --------------------------------------------------------
% \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\|/////////////////////////////////////////////////////////////////////////
% ***************************************************************************************************************************************************

\section{Introduzione e struttura dei sistemi operativi}

% ***************************************************************************************************************************************************
% -------------------------------------------------------------- DEFINIZIONI E COMPITI --------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Introduzione e compiti di un sistema operativo}
Il sistema operativo è un software che agisce da intermediario tra l’utente e l’hardware del computer, deve fornire servizi e
caratteristiche presenti a tutti i suoi utenti attraverso l'interfacciamento di hardware e applicativi e deve gestire le varie
risorse hardware a disposizione.

\subsubsection*{Funzioni del sistema operativo / problemi che deve risolvere}
\begin{itemize}
	\item fornire all'utente applicativi (programmi e comandi) per far eseguire operazioni all'elaboratore
	\item coordinare l'esecuzione dei programmi dell'utente e dei processi del sistema (es. multithreading)
	\item gestire le risorse (memoria, I/O, \dots) efficientemente e prevenire errori dal loro uso improprio
\end{itemize}

\subsubsection*{Architettura di un sistema di calcolo}
Il sistema di calcolo è l'insieme di hardware, sistema operativo, programmi di sistema e applicativi con la possibilità di
accedere alle risorse hardware. 

\subsubsection*{Struttura a cipolla}
La struttura del sistema di calcolo è descritta con il modello a cipolla, composto da una serie di gusci concentrici, che
racchiudono l’hardware, posto al centro, e i diversi strati di software che lo gestiscono/utilizzano. I gusci rappresentano
programmi, che operano a livelli diversi di interazione uomo-macchina, ogni strato sfrutta gli strati sottostanti e fornisce
funzioni per quelli superiori. L'utente interagisce solo con lo strato più esterno detto shell, mentre lo strato più
interno a diretto contatto con l'hardware è detto kernel.

I SO dei dispositivi mobili comprendono anche un middleware, ovvero uno strumento che si posiziona tra hardware e software per
semplificare la programmazione ed aumentare la portabilità siccome gli hardware sono estremamente diversificati.


% ***************************************************************************************************************************************************
% -------------------------------------------------------- CARICAMENTO DEI SISTEMI OPERATIVI --------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Caricamento del sistema operativo}
\subsubsection*{Caricamento con BIOS}
Il bootstrap consiste in tutte le operazioni e programmi che vengono eseguiti dall'accensione allo spegnimento di un computer.
In fase di accensione il SO viene caricato attraverso una procedura che utilizza il BIOS (ormai non più usata). Il BIOS
(Basic Input Output System) o firmware è salvato nella ROM ed è costituito da routine software che forniscono funzioni base
eseguibili sull'hardware. La prima procedura prevede che
\begin{itemize}
	\item[1.] il BIOS esegue il caricamento del bootloader dalla partizione MBR (Master Boot Record) del disco
	\item[2.] il bootloader inizializza (e controlla) tutte le componenti del sistema e procede al caricamento del kernel del SO
	e ne lancia l’esecuzione
	\item[3.] il kernel avvia i programmi di sistema, che garantiscono i servizi fondamentali per l’esecuzione dei programmi utente
\end{itemize}

\subsubsection*{Caricamento con UEFI}
Nei computer moderni è ancora presente il BIOS, ma la procedura UEFI (Unified Extensible Firmware Interface) ne controlla
l'esecuzione attraverso una interfaccia grafica, e ne estende le funzionalità con la possibilità di indirizzare più memoria
ed eseguire compiti più complessi come strumenti per la diagnostica e il ripristino dei dati, servizi di crittografia e
funzionalità per la gestione dei consumi. La procedura UEFI prevede che:
\begin{itemize}
	\item[1.] l'UEFI carica il bootloader dalla cartella EFI nella partizione del disco dedicata al sistema operativo (non più
	da una partizione apposita)
	\item[2.] il bootloader carica il kernel che a sua volta caricherà il resto del SO
\end{itemize}

% ***************************************************************************************************************************************************
% ---------------------------------------------------------- SERVIZI DEI SISTEMI OPERATIVI ----------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Servizi offerti dal sistema operativo}
\subsubsection*{Servizi user oriented}
\begin{itemize}
	\item \textbf{interfaccia utente}: strumento con cui l'utente interagisce con il computer, a riga di comando (Command Line
	Interface) e/o grafica (Graphical User Interface)
	\item \textbf{esecuzione di programmi}: caricare ed eseguire comandi correttamente, su richiesta dell'utente
	\item \textbf{operazioni di I/O}: interazione con le periferiche connesse
	\item \textbf{gestione del filesystem}: creare, leggere, scrivere, cancellare files e muoversi tra le directory
	\item \textbf{comunicazioni}: gestione dello scambio di informazioni tra processi in esecuzione
	\item \textbf{rilevamento di errori}: individuare e agire opportunamente se si verificano errori
\end{itemize}

\subsubsection*{Servizi per il funzionamento corretto ed efficiente del sistema}
\begin{itemize}
	\item \textbf{gestione delle risorse}: assegnazione delle risorse e monitoraggio del loro utilizzo da parte del sistema e
	degli utenti
	\item \textbf{protezione}: garantire un accesso controllato alle risorse
	\item \textbf{sicurezza}: fornire mezzi di autenticazione e proteggere le risorse da accessi illegali
\end{itemize}

\subsubsection*{Interfaccia CLI}
Interfaccia utente a riga di comando che permette all'utente di impartire comandi al sistema. Il sistema può offrire più shell,
ovvero ambienti CLI diversi (bash, zsh) e incorpora un interprete dei comandi che esegue i comandi richiesti dall'utente. I
comandi possono far parte built-in dell'interprete, oppure possono essere customizzati dall'utente.

\subsubsection*{Interfaccia GUI}
L'interfaccia grafica permette una più intuitiva iterazione con l'utente tramite mouse, tastiera e monitor. I files, le cartelle
e i programmi sono rappresentati da icone con cui è possibile interagire con il mouse. Le prime interfacce grafiche sono state
sviluppate dalla Xerox PARC di Palo Alto e sono state adottate subito dalla Apple.

\subsubsection*{Chiamate a sistema o system call}
Le chiamate a sistema sono gli strumenti che permettono di accedere ai servizi del sistema operativo, sono realizzate in linguaggi
ad alto livello (C, C++) e sono richiamate attraverso le API (Application Programming Interface). Esempi di API sono: Win64 API
per Windows, POSIX API per Unix, Linux e macOS e Java API per Java Virtual Machine.

Quando viene effettuata una chiamata al sistema, avviene il cambio di mode bit (da user mode a kernel mode) e quando la routine
del sistema termina, restituisce il risultato al programma chiamante ritorna al bit mode iniziale (da kernel mode a user mode).

Il passaggio dei parametri alle chiamate a sistema può avvenire in tre modi: salvandoli nei registri, salvandoli in un'area di
memoria e passare l'indirizzo di memoria in un registro (preferita da Linux >5 e Solari) oppure tramite lo stack

Esempi di alcune chiamate a sistema in Linux:
\begin{itemize}
	\item \texttt{fork}, \texttt{exit}, \texttt{wait/waitpid}, \texttt{exec} \texttt{execve}, \texttt{signal}, \texttt{kill} per controllo dei processi
	\item \texttt{open}, \texttt{read}, \texttt{write}, \texttt{close} per gestione dei files
	\item \texttt{ioctl}, \texttt{read}, \texttt{write} per gestione dei dispositivi
	\item \texttt{getpid}, \texttt{ps}, \texttt{alarm}, \texttt{sleep} per recupero informazioni
	\item \texttt{pipe}, \texttt{shmget}, \texttt{mmap} per comunicazione tra processi
	\item \texttt{alloc}, \texttt{free} per assegnazione e rilascio della memoria
\end{itemize}

\subsubsection*{Programmi di sistema e servizi}
I programmi di sistema sono una interfaccia conveniente e semplificativa delle system call. Vengono invocati da terminale e
sono lo strumento con cui l'utente interagisce con il sistema. Si dividono in due categorie:
\begin{itemize}
	\item \textbf{servizi in background} (servizi, sottosistemi o daemon) che vengono avviati in fase di boot e permettono il
	corretto funzionamento del sistema, vengono esegui in modalità utente
	\item \textbf{programmi applicativi} non fanno parte del sistema, ma sono scaricati dall'utente
\end{itemize}

\subsubsection*{Compilazione, ABI, linker e loader}
Il risultato della \textbf{compilazione} è specifico di ogni sistema, ovvero non è universale per tutti i SO, su Unix si utilizza il formato
ELF (Executable and Linkable Format), in Windows si usa il formato PE (Portable Executable) e in macOS si usa Mach-O.

I dettagli di come un file compilato agisce sul sistema operativo (chiamate a sistema, passaggio dei parametri, formato degli
eseguibili, gestione della memoria, \dots) sono contenute nelle \textbf{ABI} (Application Binary Interface).

Il \textbf{linker} è lo strumento che unisce i diversi file oggetto rilocabili ottenuti dalla compilazione di un determinato
programma e dalle relative librerie statiche. Nei moderni sistemi si predilige il linking dinamico delle librerie dinamiche
(DLL in Windows) che vengono caricate e condivise dai vari programmi in base alle necessità.

Il \textbf{loader} è lo strumento che carica il file eseguibile e le necessarie dipendenze dalla memoria secondaria alla memoria
primaria.


% ***************************************************************************************************************************************************
% --------------------------------------------------------- PROGETTAZIONE E SVILUPPO DEI SO ---------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Progettazione e sviluppo dei SO}
\subsubsection*{Linguaggi con cui è scritto un sistema operativo}
Il sistemi vengono sviluppati con un mix di linguaggi per favorirne la portabilità, la leggibilità e la facilità nella manutenzione:
Si usa assembly per i driver dei dispositivi, il C per il kernel e altri linguaggi di alto livello come C, C++, shell script, Python
per programmi di sistema e applicativi.

\subsubsection*{Sistemi monolitici}
Nei sistemi monolitici si ha che tutte le funzioni di gestione delle risorse sono realizzate nel kernel e i diversi moduli
sono molto legati tra di loro. Lo svantaggio è che, siccome tutti lavorano nella stessa area di memoria, un errore di un
modulo può comportare il blocco dell'intero sistema. Il vantaggio è che un sistema monolitico è molto efficiente.

\noindent
Esempi di sistemi monolitici:
\begin{itemize}
	\item \textbf{MS-DOS}: \\
	era nato con l'idea di offrire il maggior numero di funzionalità nel minor spazio possibile. Non è suddiviso in moduli e non
	c'è una netta separazione tra interfacce e funzionalità. Gli applicativi accedono direttamente alle routine di sistema del
	BIOS, senza nessuna protezione, in quanto l'Intel 8088 (hardware su cui girava MS-DOS) non aveva protezione hardware tramite
	i bit mode.
	\item \textbf{UNIX}: \\
	è un sistema scarsamente stratificato (date le limitate funzionalità hardware di quando è stato progettato) ed è diviso in
	due parti: i programmi di sistema e il kernel (che incorpora tutto ciò che si trova tra le system call e l'hardware).
\end{itemize}

\subsubsection*{Approccio stratificato}
L'approccio stratificato consiste nell'organizzare i vari moduli del sistema su più livelli in cui ogni livello può interagire
con quelli sottostanti e fornisce funzionalità e servizi per quelli più esterni. Il livello più interno 0 è l'hardware, quello
più esterno è l'interfaccia utente. Il vantaggio è nella semplicità di realizzazione e manutenzione, gli svantaggi sono la
difficile caratterizzazione degli strati (uno strato può usare solo funzionalità di quello immediatamente inferiore) e la scarsa
efficienza in quanto è necessario attraversare più strati per ogni system call.

\subsubsection*{Microkernel}
I sistemi microkernel sono composto da un kernel minimalista che si occupa solo di gestire processi, memoria e comunicazione,
mentre lascia il resto (applicativi, filesystem e device driver) al lato utente. In questo modo l'aggiunta di nuove funzionalità
(dal lato utente) non modifica il kernel, è più facile da mantenere portare su nuove architetture, è più sicuro e affidabile in
quanto poco codice viene eseguito in modalità kernel. Lo svantaggio è il possibile rallentamento causato dall'overhead tra
modalità utente e modalità kernel. Esempi di microkernel sono Windows NT, Mach (incluso in Darwin), GNU Hurd.

\subsubsection*{Kernel modulari}
I kernel modulari o Loadable Kernel Modules (LKMs) si organizzano in moduli che implementano componenti base con relative
interfacce, possono comunicare tra di loro e possono essere caricati in memoria solo quando richiesto. Rispetto all'architettura
a strati, quella a moduli è più flessibile perché non si ha l'obbligo di attraversare i diversi strati, sono facili da mantenere
e da evolvere. Esempi sono Linux (periferiche e filesystem) e Solaris.

\subsubsection*{Sistemi ibridi}
I sistemi ibridi combinano diversi approcci allo scopo di migliorare performance, manutenibilità e usabilità. Alcuni esempi sono:
\begin{itemize}
	\item \textbf{Linux e Solaris} sono costituiti da kernel monolitici, ma prevedono la possibilità di nuovi moduli da caricare
	in runtime
	\item \textbf{Windows} è di base monolitico, ma conserva alcuni comportamenti di sistemi microkernel come il supporto a
	sottosistemi separati (personalità) eseguibili in modalità utente
\end{itemize}

\subsubsection*{macOS}
\vspace{-5pt}
\begin{verbatim}
  |
  +- Darwin: core open source di macOS
  |  +- XNU: kernel ibrido "X is Not Unix"
  |  |  +- Mach: microkernel per gestione di memoria, scheduling thread, RPC e IPC
  |  |  +- BSD: sottosistema Unix-derived per gestione di filesystem, rete e API POSIX
  |  |  +- IOKit: moduli dinamici per la gestione dei driver (estensioni kernel)
  |  +- librerie C di basso livello: libc, dyld, ecc.
  |  +- utility di sistema base: shell, tool UNIX, ecc.
  +- framework grafico Cocoa: GUI, AppKit, UIKit
  +- applicazioni di sistema: Finder, Safari, ecc.
  +- servizi Apple proprietari: Spotlight, iCloud, ecc.
\end{verbatim}

\begin{itemize}
	\item Da Mac OS X (2001), il SO è costruito secondo la struttura sopra, con un kernel ibrido dotato di microkernel,
	sottosistema Unix e moduli dinamici per gestione dei driver.
	\item Le chiamate di procedura remota (RPC, Remote Procedure Calls) sono un meccanismo di comunicazione usato in informatica
	per permettere a un programma di eseguire una funzione o procedura che risiede su un altro computer o processo, come se fosse
	una chiamata locale.
	\item La comunicazione tra processi (IPC, Inter-Process Communication) è un insieme di meccanismi che permettono di gestire
	lo scambio di dati e informazioni tra due processi concorrenti (pipe, named pipe, message queue, shared memory, semafori,
	socket e signal).
	\item Le API POSIX (Portable Operating System Interface) sono un insieme di specifiche standard per le interfacce di
	programmazione dei sistemi operativi, progettate per garantire la portabilità delle applicazioni tra diversi sistemi
	Unix-like e altri sistemi compatibili. Grazie a POSIX, gli sviluppatori possono creare software che funziona su Linux,
	macOS, BSD e altri sistemi conformi, senza dover riscrivere codice specifico per ogni piattaforma.
	\item Il framework grafico Cocoa è l'insieme degli strumenti per creare interfacce grafiche nativamente in macOS. L'interfaccia
	utente predefinita di sistema si chiama Aqua che viene mantenuta sempre aggiornata e determina il look e il feel del sistema.
\end{itemize}

\subsubsection*{iOS}
iOS si basa sullo stesso core di macOS chiamato Darwin integrato con:
\begin{itemize}
	\item il framework grafico Cocoa Touch apposito per i dispositivi touch
	\item i media service per le applicazioni multimediali (grafica, video, audio)
	\item i core services per supporto al cloud computing e ai database
\end{itemize}

\subsubsection*{Android}
Android è un sistema sviluppato dalla Open Handset Alliance guidata da Google, insieme a Asus, Htc. Intel, Motorola, Qualcomm,
T-Mobile, Samsung e Nvidia. È un sistema a struttura stratificata basato su un kernel Linux modificato. I vari programmi e servizi
vengono eseguiti sull'ART (Android Run Time), ovvero su macchina virtuale. Le app sono sviluppate in Java e tradotte in eseguibili
per la ART virtual machine. È disponibile anche l'interfaccia JNI (Java Native Interface) per bypassare la ART e avere accesso
diretto all'hardware. Nel sistema è incluso uno strato di astrazione dell'hardware HAL (Hardware Abstaction Layer).

\subsubsection*{Windows Subsystem for Linux - WSL}
Grazie all'architettura ibrida di Windows è possibile eseguire sottosistemi in modalità utente in grado di emulare altri SO. Nel
caso del WSL, viene avviata una istanza di Linux in grado di eseguire le applicazioni native di Linux grazie alla presenza dei
servizi kernel LXCore e LXSS che traducono le system call Linux in system call Windows (es. fork in CreateProcess) e in mancanza
di una corrispondenza esatta, fornisce una funzionalità equivalente.

\subsubsection*{Debugging}
Il debugging è l'attività di individuazione e risoluzione dei bachi (bug) e di performace tuning. Il SO genera diversi file con
i dati runtime dei processi attivi e dell'intero sistema:
\begin{itemize}
	\item \textbf{file di log}: informazioni sugli errori durante l'esecuzione di un processo
	\item \textbf{core dump}: immagine della memoria di un processo al momento della sua terminazione anomala
	\item \textbf{crash dump}: immagine completa della memoria nell'istante in cui si verifica un crash, ovvero un guasto nel kernel,
	spesso si ricorrono a tecniche particolari (salvare l'immagine in un'area di memoria dedicata) per evitare di compromettere
	il filesystem in caso di kernel in stato inconsistente
\end{itemize}

\subsubsection*{Performance tuning}
I problemi che coinvolgono le prestazioni del sistema sono considerati bachi e il performance tuning si occupa di individuarli
e risolverli per ottimizzare le prestazioni ed eliminare i colli di bottiglia. Ciò viene fatto tramite strumenti per monitorare
gli eventi in rilievo, le risorse in uso (es. comando top di Unix) e le system call più frequenti.

\newpage

% ***************************************************************************************************************************************************
% ------------------------------------------------------------ GESTIONE DELLE PERIFERICHE -----------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Gestione delle periferiche e delle risorse}
\subsubsection*{Interfacciamento tramite driver, controller e interrupt}
L'interfacciamento tra hardware e programmi applicativi avviene secondo il seguente schema:
\[\text{applicativi} \;\;\leftrightarrow\;\; \text{kernel} \;\;\leftrightarrow\;\; \text{kernel I/O subsystem} \;\;\leftrightarrow\;\; \text{drivers} \;\;\leftrightarrow\;\; \text{controllers} \;\;\leftrightarrow\;\; \text{risorsa/dispositivo}\]
\begin{itemize}
	\item \textbf{controller}: componente hardware specifico per ogni risorsa che gestisce un buffer per l'input e l'output dei
	dati dalla risorsa all'elaboratore
	\item \textbf{driver}: componente software specifico di ogni risorsa che permette al kernel di interfacciarsi con un
	determinato controller e fornisce le indicazioni sullo scambio dei dati tra elaboratore e risorsa
\end{itemize}

\subsubsection*{Device driver}
Un device driver (o controllore di periferica), è un componente software di basso livello utilizzato per comunicare con le periferiche
connesse al computer.
\begin{itemize}
	\item \textbf{driver di sistemi embedded}: tutto il software è un unico programma compilato e caricato in ROM, il driver non è
	altro che una routine del programma che si interfaccia con l'hardware da pilotare
	\item \textbf{driver in kernel monolitici} (es. Linux): i driver sono moduli compilati insieme al kernel, se si vuole collegare
	una periferica per cui non è presente un driver, è necessario aggiungerlo e ricompilare il kernel (dalle nuove versioni non
	è più richiesta la ricompilazione), questo porta al vantaggio che i driver già presenti nel kernel sono testati dai programmatori
	del sistema operativo offrendo maggiore efficienza e affidabilità
	\item \textbf{driver in kernel ibridi} (es. Windows): i driver sono file binari caricati dinamicamente dal kernel al momento
	del bisogno, questa scelta permette una maggiore compatibilità e flessibilità nella gestione delle periferiche in quanto è
	sufficiente che il produttore fornisca il driver per la propria periferica e si è certi di poterla utilizzare, lo svantaggio
	è che i driver potrebbero non essere ottimizzati ed efficienti, non essendo parte del kernel
\end{itemize}

\subsubsection*{Interrupt}
La comunicazione tra controller e driver/kernel avviene tramite gli interrupt. Esiste un vettore con puntatori alle procedure da
eseguire quando si riceve un interrupt (chiamate Interrupt Service Routines) e che gestiscono i flussi di dati tra risorse e sistema.

\subsubsection*{Input/Output}
\begin{itemize}
	\item \textbf{gestione sincrona}: la CPU aspetta fino a quando il dato non è pronto in quanto è la CPU che gestisce i trasferimenti
	\item \textbf{gestione asincrona}: la CPU delega al DMA lo spostamento dei dati e nel frattempo può eseguire altre operazioni
\end{itemize}

\subsubsection*{DMA, RDMA e GPU Direct Storage}
Il DMA (Direct Memory Access) è un componente hardware che esegue il trasferimento di blocchi di dati dalla memoria secondaria o
dal buffer locale di qualche dispositivo alla memoria principale. Viene gestito tramite interrupt e funziona come segue:
\begin{itemize}
	\item[1.] vengono specificati l'indirizzo, la dimensione dei dati sorgente e l'indirizzo di destinazione
	\item[2.] il DMA si occupa del trasferimento, inviando un interrupt per ogni blocco trasferito, lasciando il processore
	libero di eseguire altri processi
\end{itemize}
Alcune varianti del DMA applicate a casi particolari:
\begin{itemize}
	\item \textbf{RDMA o Remote Direct Memory Access} è un sistema che permette il trasferimento dei dati tra le RAM di diversi elaboratori
	collegati insieme, in ambito multicomputer con parallelizzazione
	\item \textbf{GPU Direct Storage} è un protocollo che prevede il trasferimento dei dati dalla memoria secondaria direttamente alla GPU,
	senza passare per la RAM, introdotto in Windows11 e inizialmente sviluppato per XBox.
\end{itemize}


% ***************************************************************************************************************************************************
% ------------------------------------------------------------ STRUTTURE DATI DEL KERNEL ------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Strutture dati del kernel}
\subsubsection*{Strutture dati classiche}
\begin{itemize}
	\item \textbf{array}: semplice struttura dati in cui ogni elemento è direttamente accessibile tramite un indice. La
	memoria principale è costruita come un array in cui si accede alle celle tramite un indirizzo di memoria
	\item \textbf{liste concatenate}: possono contenere dati di diversa natura e dimensione e sono talvolta utilizzate
	direttamente dagli algoritmi del kernel, ad esempio nell’allocazione concatenata di file
	\item \textbf{stack}: struttura LIFO (Last In First Out) utilizzata ad esempio per le chiamate a funzione (RDA) e il
	cambio di contesto
	\item \textbf{code}: struttura FIFO (First In First Out) utilizzata per gestire i documenti inviati ad una stampante
	o i processi in attesa di ottenere l’accesso alla CPU
	\item \textbf{alberi}: strutture basate sulla relazione causale padre-figlio, in genere si utilizzano gli alberi binari
	di ricerca ad esempio in Linux per l'algoritmo di scheduling della CPU
\end{itemize}

\subsubsection*{Tabelle e funzioni hash}
Una funzione hash è una funzione che trasforma ogni valore di chiave in un indirizzo o bucket.
\begin{itemize}
	\item le funzioni di hash non sono iniettive per cui possono verificarsi \textbf{collisioni} se due chiavi distinte vengono
	mappate sullo stesso indirizzo, trovare funzioni che riducono al minimo le collisioni è molto complesso e molto dispendioso,
	per gestire le collisioni si utilizzano per ogni bucket delle catene o liste di trabocco (liste concatenate) per memorizzare
	le chiavi che collidono 
	\item la \textbf{capacità} di un bucket è il numero di chiavi che può contenere (in caso di collisioni)
	\item l'\textbf{overflow} si verifica quando si tenta di inserire una chiave all'interno di un bucket già pieno
	\item l'\textbf{area di overflow} è un'area di memoria utilizzata per memorizzare i dati che hanno generato overflow
	\item l'\textbf{area primaria} è l'area di memoria con i bucket indirizzabili dalla tabella di hash
\end{itemize}
Per convertire una stringa alfanumerica \(s\) si sceglie una determinata funzione che mappa ogni carattere in un intero distinto
\(s_i\) e, dopo aver scelto una base \(b\), si associa il corrispettivo peso ad ogni carattere. Infine si sommano i risultati
ottenuti: \[k(s) = \sum_{i=0}^{n-1} s_i \cdot b^i\]


% ***************************************************************************************************************************************************
% -------------------------------------------------------------- PROTEZIONE E SICUREZZA -------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Protezione e sicurezza}
\subsubsection*{Protezione delle risorse}
Il SO deve controllare che i programmi accedano solo alle risorse (file, segmenti di memoria, CPU, \dots) di cui hanno ottenuto
l'apposita autorizzazione. Inoltre deve verificare che solo gli utenti autorizzati accedano alle risorse di cui hanno accesso.

\subsubsection*{Mode bit}
Ogni operazione è associata ad un livello di protezione detto mode bit. Il mode bit è gestito via hardware e indica lo stato di
protezione entro cui una determinata operazione può essere eseguita. 
\begin{itemize}
	\item \textbf{user mode} è uno stato di privilegio caratterizzato da un numero relativamente basso di privilegi verso la
	memoria, l'hardware e altre risorse
	\item \textbf{kernel mode} è lo stato di privilegio massimo riservato all'esecuzione del kernel. Il codice in linguaggio
	macchina eseguito in tale modalità ha accesso illimitato alla memoria, all'hardware e alle altre risorse
\end{itemize}
Se ci si trova in uno stato con alto livello di protezione (user mode) e si desidera eseguire un'operazione che richiede un
livello inferiore (kernel mode), è necessario passare ad un mode bit inferiore tramite un processo di \textbf{trap}. Una volta
completata l'operazione si effettua un processo di \textbf{return} per ripristinare il livello di protezione superiore.
Ogni system call effettua il passaggio in modalità kernel; il ritorno dalla chiamata riporta il sistema in modalità utente.

\subsubsection*{Sicurezza - Protezione da attacchi informatici}
Il SO deve implementare dei sistemi di difesa per contrastare attacchi interni ed esterni classificati in:
\begin{itemize}
	\item \textbf{denial of service}: malfunzionamento dovuto ad un attacco informatico in cui si esauriscono deliberatamente
	le risorse di un sistema di calcolo che fornisce un servizio, fino a renderlo non più in grado di erogare il servizio
	\item \textbf{trojan}: programmi che hanno una funzione conosciuta legittima e una funzione dannosa nascosta
	\item \textbf{worm}: malware (software usato per disturbare le operazioni svolte da un computer, rubare informazioni
	sensibili, accedere a sistemi informatici privati, o mostrare pubblicità indesiderata) in grado di autoreplicarsi
	\item \textbf{virus}: porzioni di codice dannoso che si legano ad altri programmi del sistema per diffondersi, un virus
	può anche essere un malware
\end{itemize}
Gli attacchi sono svolti da:
\begin{itemize}
	\item \textbf{hacker}: pirata informatico che si impegna nell’affrontare sfide intellettuali per aggirare o superare
	creativa mente le limitazioni di accesso ai sistemi per esplorare, divertirsi, apprendere, senza creare danni reali
	\item \textbf{cracker}: chi si ingegna per eludere blocchi imposti da qualsiasi software al fine di trarne guadagno
\end{itemize}


% ***************************************************************************************************************************************************
% ---------------------------------------------------------- VIRTUALIZZAZIONE ED EMULAZIONE ---------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Virtualizzazione ed emulazione}
\subsubsection*{Virtualizzazione in generale}
La virtualizzazione/emulazione è una tecnica che permette di eseguire un sistema operativo come applicazione all’interno di un
altro SO attraverso una macchina virtuale (VM). La VM crea un ambiente virtuale isolato che riproduce tipicamente il comportamento
di una macchina fisica grazie all'assegnazione di risorse hardware (porzioni di disco rigido, RAM e CPU) gestite dall'hypervisor
o Virtual Machine Manager (VMM).

Tra i vantaggi vi è il fatto di poter offrire contemporaneamente ed efficientemente a più utenti diversi ambienti operativi
separati, attivabili su richiesta, senza sporcare il sistema fisico reale con partizionamenti del disco rigido oppure ricorrendo
ad ambienti clusterizzati su sistemi server. Lo svantaggio è che, essendo le macchine virtuali isolate, non possono condividere
le risorse nativamente, a meno che non si utilizzino determinati software come Virtio.

La virtualizzazione (per le CPU che la supportano) può essere vista come una terza modalità del mode bit con più privilegi dei
processi utente in quanto lavora attivamente con le risorse assegnate, ma meno del kernel del SO ospitante in quanto deve
sempre sottostare al kernel.

\subsubsection*{Virtualizzazione vs emulazione}
L'emulazione è il processo per cui vengono riprodotte risorse hardware simulate che non corrispondo necessariamente
all'architettura reale dell'elaboratore (es. emulazione x86 su ARM). Questo processo è più costoso in quanto le istruzioni
da eseguire sono interpretate, ma permette di avere a disposizione molte architetture differenti.

La virtualizzazione consiste nel riservare parte delle risorse dell'hardware reale per l'ambiente virtualizzato. In questo modo
non è necessario tradurre le istruzioni da una architettura ad un'altra, rendendo l'esecuzione più rapida, ma è possibile eseguire
solo codice compilato per l'architettura reale in possesso.


% ***************************************************************************************************************************************************
% --------------------------------------------------------- SISTEMI EMBEDDED ED OPEN SOURCE ---------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Sistemi embedded}
I sistemi embedded sono sistemi ubiquitari, ovvero presenti ovunque (elettrodomestici, auto, robot aziendali), sono eseguiti su
sistemi rudimentali e hanno le seguenti caratteristiche:
\begin{itemize}
	\item sistemi standard che girano su elaboratori general-purpose con implementate specifiche funzionalità
	\item sistemi special-purpose che girano su microprocessori
	\item Application Specific Integrated Circuit (ASIC) senza un vero SO
\end{itemize}
Le applicazioni prevedono dei requisiti stringenti sul tempo con cui determinate operazioni devono essere portate a termine, ovvero
sono sistemi hard real-time.

\subsection{Sistemi operativi open source}
I sistemi operativi open source sono sistemi che vengono distribuiti sia in formato binario compilato, sia in codice sorgente.
Non è necessario effettuare il reverse engineering per comprendere il funzionamento del sistema. Si forma una comunità di
programmatori e aziende che contribuiscono allo sviluppo, al debugging, all’assistenza e al supporto gratuito agli utenti.
Il codice più sicuro e i bug sono scoperti e risolti velocemente.

\subsubsection*{Richard Stallman, GNU e Linux}
Richard Stallman nel 1984 da origine al progetto GNU (GNU is Not Unix), ovvero l'idea di ricreare un intero sistema operativo
analogo a UNIX, ma libero, con licenza GLP (General Public Licence). La GPL indica che ogni componente software può essere
utilizzata, modificata e distribuita mantenendo sempre la licenza GPL, ovvero non è possibile utilizzarlo in codice proprietario.
Ad oggi il progetto GNU ha numeri strumenti compatibili con Unix, ma il kernel Hurt (GNU) è ancora in fase di sviluppo. Per i
sistemi operativi liberi si utilizza il kernel Linux sviluppato da Linus Torvald usando strumenti di GNU, ma che non fa parte
del progetto GNU.

\subsubsection*{Open source e software libero}
Il software libero (GLP) indica che può essere utilizzato, modificato e distribuito liberamente, sempre sotto licenza GPL, ovvero
non può mai diventare software proprietario. Il software open source è analogo al software libero, solo che può essere anche
utilizzato in progetti proprietari.

\subsubsection*{Esempi di sistemi operativi open source / liberi}
\begin{itemize}
	\item \textbf{Linux}: open source con alcune distribuzioni libere e altre solo open source
	\item \textbf{Windows}: proprietario e closed-source
	\item \textbf{macOS}: ibrido in quanto basato su kernel Darwin open-source basato su UNIX BSD, con l'aggiunta di componenti proprietarie
	\item \textbf{UNIX BSD}: derivato da Unix, non è open source in quanto è richiesta la licenza, ma era inizialmente distribuito
	insieme al sorgente, esistono diverse distribuzioni (FreeBSD, NetBSD, \dots)
	\item \textbf{MINIX}: sistema operativo sviluppato da Andrew Tanenbaum in supporto al suo corso universitario, ma impiegato
	a sua insaputa all'interno dell'Intel Management Engine, data la sua leggerezza
\end{itemize}

\newpage


% ___________________________________________________________________________________________________________________________________________________
% /////////////////////////////////////////////////////////////////////////|\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
% ----------------------------------------------------------------- RIPASSO HARDWARE ----------------------------------------------------------------
% \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\|/////////////////////////////////////////////////////////////////////////
% ***************************************************************************************************************************************************

\section{Ripasso Hardware}

% ***************************************************************************************************************************************************
% ----------------------------------------------------------------------- CPU -----------------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{CPU}
\subsubsection*{Struttura della CPU}
La CPU o Control Proceccing Unit è l'unità di calcolo e controllo dell'elaboratore. È composta da:
\begin{itemize}
	\item \textbf{Control Unit o CU}: unità di controllo che comprende il Program Counter e Instruction Register
	\item \textbf{Arithmetic Logic Unit o ALU}: unità che esegue operazioni matematiche e logiche
	\item \textbf{registri}: aree di memoria interne al chip, utilizzate nell'esecuzione delle istruzioni, come Program Counter
	(PC), Instruction Register (IR), Memory Address Register (MAR), Memory Data Register (MDR) e altri registri per gli operandi
	\item \textbf{bus dei segnali di controllo}: trasferimento unidirezionale di segnali di controllo dal processore alla memoria (read/write)
	\item \textbf{bus degli indirizzi}: trasferimento unidirezionale degli indirizzi dal processore alla memoria
	\item \textbf{bus dei dati}: trasferimento bidirezionale dei dati tra processore e memoria
\end{itemize}

\subsubsection*{Funzionamento}
Alcune nomenclature sul funzionamento:
\begin{itemize}
	\item \textbf{fetch-decode-execute}: ciclo di valutazione delle istruzioni in una CPU
	\item \textbf{data path}: processo che comprende il recupero dei dati dai registri, l'esecuzione dell'operazione da eseguire
	da parte della ALU e memorizzazione del risultato sul nuovo registro; il ciclo di data path corrisponde al ciclo di clock nelle
	architetture non parallelizzate
	\item \textbf{durata istruzione ISA}: ogni istruzione viene eseguita in un multiplo di cicli di data path
\end{itemize}

\subsubsection*{Prestazioni}
\begin{itemize}
	\item \textbf{tempo di esecuzione} dato dal \(T_\text{clock}\) tempo di un ciclo di clock o di data path, da \(N_i\) numero
	di istruzioni di tipo \(i\) e da \(CPI_i\) numero di cicli di clock per istruzioni di tipo: \(i\) \[T_\text{exec} = T_\text{clock} \cdot \sum_{i=0}^{n} N_i \cdot CPI_i\]
	\item \textbf{MIPS o Mega Instructions Per Second} indica il numero di milioni di istruzioni eseguibili in un secondo non è
	molto preciso in quanto non tiene conto delle istruzioni offerte, della variazione di \(CPI\) per le diverse istruzioni e
	della velocità del buffer, si calcola come segue: \[M_\text{ega} I_\text{nstructions} P_\text{er} S_\text{econd} = \frac{\text{freq. di clock}}{10^6 \cdot CPI}\]
	\item \textbf{MFLOPS o Mega Floating Point operations Per Second} indica il numero di operazioni in virgola mobile a 32 bit
	che vengono eseguite in un secondo
	\item \textbf{LINPACK benchmark} misura le operazioni in virgola mobile a 64 bit
	\item \textbf{Speedup} misura l'aumento di prestazioni in percentuale \[\text{SpeedUp} = \frac{\text{Prest.} A - \text{Prest.} B}{\text{Prest.} B} = \frac{T_B - T_A}{T_A} \qquad \text{con} \quad \text{Prestazione} = 1/T_\text{esecuzione}\]
	\item \textbf{Legge di Amdhal} indica il miglioramento in funzione del ruolo del componente nel sistema con \(p\) tempo di 
	utilizzo della parte migliorata e \(a\) accelerazione dovuta al miglioramento \[T_\text{finale} = \frac{p}{a} \; T_\text{iniziale} + (1-p) \; T_\text{iniziale}\]
\end{itemize}
In generale per migliorare le prestazioni di una CPU è possibile agire:
\begin{itemize}
	\item riducendo il numero di cicli per istruzioni ISA
	\item aumentando la frequenza di clock
	\item introducendo il parallelismo (a livello di istruzioni con pipeline e superscalari o a livello di core/CPU)
\end{itemize}


% ***************************************************************************************************************************************************
% ----------------------------------------------------------- MEMORIA, CACHE E FILE SYSTEM ----------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Memoria}
\subsubsection*{Gerarchia delle memorie}
La memoria si classifica in una struttura gerarchica in ordine decrescente di prestazioni e costo:
\begin{itemize}
	\item[1.] registri (volatile)
	\item[2.] cache su più livelli (volatile)
	\item[3.] memoria principale (volatile), es. RAM
	\item[4.] memoria a stato solido es. DRAM, NVRAM, SSD, Flash
	\item[5.] disco rigido
	\item[6.] nastri magnetici
\end{itemize}

\subsubsection*{Gestione della memoria}
Il SO è responsabile delle seguenti attività connesse alla gestione della memoria centrale:
\begin{itemize}
	\item[1.] tener traccia di quali parti della memoria sono attualmente usate e da chi (controllare l'accesso alla memoria e
	garantire la versione più recente di ogni file sul disco alle applicazioni che lo richiedono)
	\item[2.] decidere quali (parti di) processi caricare in memoria quando vi è spazio disponibile
	\item[3.] allocare e deallocare lo spazio di memoria secondo necessità
\end{itemize}

\subsubsection*{Caching}
Il concetto di caching consiste nel creare una copia di dati su un supporto di memoria più veloce, ad esempio dal disco alla RAM,
o dalla RAM alla cache. Quando il computer deve accedere alla memoria, per prima cosa controlla i supporti più veloci (registri) 
e, in assenza del dato, si passa al livello inferiore (cache, RAM, HDD/SSD). Per una migliore prestazione si cerca di avere almeno
tra l'80 \% e il 99 \% degli accessi dalla cache.

\subsubsection*{Buffering}
Il buffering è un processo per cui si utilizza un’area di memoria chiamata buffer per salvare temporaneamente i dati trasferiti
tra dispositivi con velocità diverse (es. RAM e disco), i dati per dispositivi di output o le modifiche ai file prima del
salvataggio su disco. In questo modo si migliora l’efficienza del trasferimento e salvataggio dei dati. Differisce dalla cache
in quanto si trova nella RAM e funge da area in cui la CPU può memorizzare temporaneamente dati prima che essi vengano trasferiti
o riprodotti.

\subsubsection*{Spooling}
Lo spooling è una tecnica che consiste nel mettere in coda (spool) le richieste di I/O in un'area di memoria dedicata in modo
che il sistema operativo le riesca a gestire in modo sequenziale. In questo modo è possibile gestire più attività di I/O
contemporaneamente, migliorando l'efficienza del sistema.

\subsubsection*{I/O Interleaving}
L'I/O Interleaving consiste nel trattare le operazioni di lettura o scrittura che coinvolgono più dispositivi di I/O in modo
sequenziale, alternando le operazioni tra di essi anziché completarle su un dispositivo prima di passare al successivo. Questo
permette al sistema di lavorare, ad esempio su settori di dischi diversi contemporaneamente, riducendo il tempo complessivo
necessario per completare l’operazione. In generale, l’interleaving implica la disposizione non contigua dei dati per migliorare
le prestazioni.

\subsubsection*{Memoria cache}
La memoria cache è una piccola memoria molto veloce e costosa affiancata alla CPU per ridurre notevolmente il tempo impiegato
per gli accessi alla RAM. In pratica vengono memorizzate delle copie delle pagine in RAM (dette linee di cache) in modo da poterci
accedere velocemente senza sprecare cicli di clock per leggerle dalla RAM. Il processore tenta di leggere sempre i dati dalla
cache, se il dato è effettivamente presente si ha un cache hit, altrimenti si ha un cache miss ed è necessario caricare in memoria
la pagina con il dato richiesto.
\newpage
\noindent
Il principio di utilizzo della cache si basa su:
\begin{itemize}
	\item \textbf{località spaziale}: ovvero se viene richiesto un dato, è probabile che verranno richiesti anche i dati limitrofi,
	infatti vengono caricate le intere pagine di RAM (delle linee di cache) e non i singoli dati
	\item \textbf{località temporale}: ovvero se in un istante si richiede un determinato dato, è probabile che verrà riutilizzato
	in un istante successivo, normalmente si usa la politica di rimpiazzo LRU
\end{itemize}
\noindent
Spesso si utilizzano più livelli di cache per un migliore trade-off tra velocità e costi:
\begin{itemize}
	\item \textbf{cache L1}: suddivisa in L1-I (istruzioni) e L1-D (dati) situata all'interno dei core (16KB to 128KB)
	\item \textbf{cache L2}: più lenta ed economica, cache condivisa tra i diversi core (256KB and 1MB)
	\item \textbf{cache L3}: più lenta ed economica, situata nella motherboard (2MB to 32MB)
\end{itemize}

\subsubsection*{Gestione del file system}
Per gestione del file system significa gestione dell'organizzazione dei file nel disco, il SO è responsabile di:
\begin{itemize}
	\item[1.] creazione e cancellazione di file e directory
	\item[2.] supporto alle funzioni elementari per la manipolazione di file e directory
	\item[3.] associazione dei file ai dispositivi di memoria secondaria
	\item[4.] backup di file su dispositivi stabili di memorizzazione
\end{itemize}


% ***************************************************************************************************************************************************
% ------------------------------------------------------------ CONCETTI DI SISTEMI E RETI -----------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Concetti di sistemi e reti}
\subsubsection*{Sistemi distribuiti}
I sistemi distribuiti sono un insieme (eterogeneo) di calcolatori con memoria e clock indipendente (non condivisi) che sono
connessi attraverso una rete di comunicazione di uno dei seguenti tipi (in base all'estensione):
\begin{itemize}
	\item[1.] Wide Area Network (WAN)
	\item[2.] Metropolitan Area Network (MAN)
	\item[3.] Local Area Network (LAN)
	\item[4.] Personal Area Network (PAN)
\end{itemize}
La comunicazione avviene secondo un dato protocollo (TCP/IP è il più diffuso). Un sistema distribuito fornisce agli utenti
l’accesso a varie risorse condivise di sistema in modo da consentire di accelerare l’elaborazione, aumentare la disponibilità
di dati e migliorare l’affidabilità. In base al ruolo degli elaboratori nelle reti, queste vengono classificate in:
\begin{itemize}
	\item \textbf{client-server}: i pc fungono da client che richiedono servizi al server
	\item \textbf{peer-to-peer (P2P)}: non esiste la distinzione tra client e server (es. Napster, eMule, servizi VoIP come Skype;
	bittorrent non è P2P puro perché necessita di server per connettersi alla rete)
\end{itemize}

\subsubsection*{Cloud computing}
Il cloud computing indica l'insieme di piattaforme e tecnologie che permettono di archiviare file o di sviluppare/utilizzare
programmi e applicazioni direttamente sui server di chi fornisce il servizio, anziché sul proprio dispositivo. Pertanto il cloud
computing è una tecnica che permette la fruizione di risorse computazionali, di storage e di applicazioni come servizi di rete.
Alcuni esempi di cloud computing sono Google Drive ed EC2 (Elastic Compute Cloud) di Amazon. Le tipologie di cloud computing sono:
\begin{itemize}
	\item[1.] \textbf{cloud pubblico}: disponibile attraverso internet a chiunque si abboni al servizio
	\item[2.] \textbf{cloud privato}: gestito da un’azienda ad utilizzo interno
	\item[3.] \textbf{cloud ibrido}: comprende componenti sia pubbliche che private
	\item[4.] \textbf{SaaS} (Software as a Service): applicazioni fruibili via unternet (es. word processor, fogli di calcolo)
	\item[5.] \textbf{PaaS} (Platform as a Service): ambiente software per usi applicativi via internet (server database)
	\item[6.] \textbf{IaaS} (Infrastructure as a Service): server o storage accessibili via internet (spazio per backup)
\end{itemize}


% ***************************************************************************************************************************************************
% ------------------------------------------------------- SISTEMI MULTIPROCESSORI/SUPERSCALARI ------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Sistemi multiprocessore, multiscalare e parallelismo}
\subsubsection*{Introduzione al parallelismo}
Caratteristiche dei diversi tipi di parallelismo:
\begin{itemize}
	\item \textbf{loosely coupled}: poche CPU indipendenti collegate a bassa velocità
	\item \textbf{strongly coupled}: tanti piccoli componenti (ALU, core, \dots) collegati ad alta velocità
	\item \textbf{course grained}: il software parallelizzato è grande e non richiede interazioni con altri software
	\item \textbf{fine grained}: si parallelizzano piccole istruzioni che richiedono interazioni costanti
	\item \textbf{interconnessione statica}: se determinata a priori e non cambia nel tempo
	\item \textbf{interconnessione dinamica}: se si basa sulle necessità del momento, con apparecchi come switch
\end{itemize}

\subsubsection*{Sistemi superscalari - a parallelismo di istruzioni}
Le architetture superscalari implementano un parallelismo a livello di istruzioni. Permettono di eseguire o iniziare a eseguire
contemporaneamente più stati diversi (es. recupero operandi, decodifica, esecuzione, \dots) di diverse istruzioni distribuite a
diverse unità di elaborazione all'interno del singolo chip.

\subsubsection*{Sistemi Hyper-Threading o multithreading}
Nei sistemi Hyper-Threading o multithreading, i singoli core dispongono di due unità di elaborazione in grado di eseguire
contemporaneamente due thread in parallelo sullo stesso core.

\subsubsection*{Sistemi multicore}
Un'architettura multicore si raggruppano diverse unità di calcolo (core) in un singolo chip. È più efficienti, perché le
comunicazioni, sul singolo chip, sono più veloci e un chip multicore usa molta meno potenza di diversi chip single core.
I diversi core nel singolo chip hanno un livello di cache condiviso (L2 o superiore).

\subsubsection*{Sistemi con coprocessori}
Un'architettura con coprocessori consiste nell'affiancare un'altra unità di elaborazione esterna al processore per svolgere compiti
specifici come elaborazione grafica (GPU), processi di rete (schede di rete), crittografia (criptoprocessori).

\subsubsection*{Sistemi multiprocessore}
Un'architettura multiprocessore è costituita da più processori su una unica scheda madre che condividono la stessa memoria.
Bisogna fare attenzione nella gestione del traffico dei dati tra i diversi processori e all'assegnazione delle risorse.
L'elaborazione può essere:
\begin{itemize}
	\item \textbf{asimmetrica}: ad ogni processore viene assegnato un compito specifico e un processore principale sovrintende
	all’intero sistema
	\item \textbf{simmetrica}: ogni processore è abilitato all’esecuzione di tutte le operazione del sistema
\end{itemize}

\subsubsection*{Sistemi multicomputer}
Un'architettura multicomputer è una struttura costituita da più elaboratori (ciascuno indipendente con la propria CPU e memoria)
collegati insieme, di solito condividono la stessa memoria secondaria.. La gestione del traffico dei dati tra i diversi processori
è particolarmente ostico da gestire, però hanno il vantaggio di essere più facili ed economici da implementare rispetto ai sistemi
multiprocessore. Esistono alcuni indici di classificazione dei multicomputer:
\begin{itemize}
	\item \textbf{grado o fanout}: numero di interconnessioni di ogni unità, serve per calcolare il fault tollerance
	\item \textbf{diametro}: distanza massima tra due nodi qualsiasi della rete
	\item \textbf{dimensionalità}: numero di assi diversi su cui si sviluppa la rete
	\item \textbf{scalabilità}: proporzionalità tra il numero di processori e le prestazioni della rete
\end{itemize}

\newpage

Alcuni esempi di interconnessioni:
\begin{itemize}
	\item \textbf{stella}: tutti i nodi sono connessi ad un nodo centrale, diametro = 2, dimensione = 0
	\item \textbf{albero}: struttura ad albero, diametro = 2h, dimensione = 0 
	\item \textbf{interconnessione completa}: tutti i nodi sono connessi tra di loro, diametro = 1, dimensione = 0
	\item \textbf{anello}: i nodi sono posizionati su una circonferenza: diametro = \(2P/2\), dimensione = 1
	\item \textbf{griglia}: nodi posizionati in una griglia, diametro = \(2(l-1)\), dimensione = 2
	\item \textbf{toroide2D}: griglia con interconnessioni tra nodi esterni, diametro = \(l\), dimensione = 2
	\item \textbf{cubo}: nodi disposti su un cubo, diametro = 3, dimensione = 3
	\item \textbf{ipercubo}: nodi disposti su un ipercubo, buon compromesso di scalabilità in quanto il diametro aumenta
	logaritmicamente in base al numero di processori, diametro = 4, dimensione = 4
	\item \textbf{toroide3D}: nodi disposti su una griglia tridimensionale, in quanto è un buon compromesso tra diametro della
	rete e numero di connessioni, diametro = \dots, dimensione = 3
\end{itemize}

\subsubsection*{Sistemi cluster}
Un cluster è un particolare tipo di multicomputer con particolare attenzione alle interconnessioni e alla coordinazione delle
diverse unità. Per usufruire delle potenzialità dei cluster in ambito High Performance Computer (HPC), è necessario che i processi
siano scritti per essere parallelizzati. In base alla gestione delle interconnessioni si differenziano in:
\begin{itemize}
	\item \textbf{clustering asimmetrico}: un calcolatore rimane nello stato di attesa attiva mentre gli altri eseguono le
	applicazioni, il calcolatore in stand by controlla gli altri nodi e si attiva nel caso di malfunzionamenti
	\item \textbf{clustering simmetrico}: tutti i nodi eseguono le applicazioni e si controllano reciprocamente, attraverso ad
	esempio il protocollo NUMA (Non Uniform Memory Acccess system)
\end{itemize}

\subsubsection*{Speedup per aumento delle CPU}
Il tempo di esecuzione di un frammento di codice (parzialmente o totalmente parallelizzato) in un'architettura in grado di eseguire
operazioni parallele viene:
\[S_\text{peedUp} = \frac{T_\text{seq}}{T_\text{par}} = \frac{n}{1- (n-1)f} \qquad T_\text{par} = f \cdot T_\text{seq} \; \frac{(1-f)T_\text{seq}}{n} \qquad
\begin{aligned}
T_\text{seq} &= \text{tempo exec. con 1 CPU} \\
T_\text{par} &= \text{tempo exec. con } n \text{ CPU} \\
n &= \text{numero CPU} \\
f &= \text{frazione sequenziale del codice}
\end{aligned}\]

\subsubsection*{Classificazione tassonomica di Flynn (1972)}
\begin{center}
	\begin{minipage}{0.39\textwidth}
		\begin{itemize}
			\item \textbf{SISD}: single instruction sequence, single data sequence
			\item \textbf{SIMD}: single instruction sequence, multi data sequence
			\item \textbf{MISD}: multi instruction sequence, single data sequence
			\item \textbf{MIMD}: multi instruction sequence, multi data sequence
		\end{itemize}
	\end{minipage}
	\begin{minipage}{0.6\textwidth}
		\centering
		\includegraphics[width=0.85\textwidth]{architetture parallele.png}
	\end{minipage}
\end{center}

\newpage

% ***************************************************************************************************************************************************
% ----------------------------------------------------------------------- GPU -----------------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Coprocessori: GPU, TPU, FPGA}
\subsubsection*{Evoluzione della GPU per general purpose calculation GP-GPU}
All'inizio le GPU erano specifiche per eseguire calcoli relativi alla parte grafica (colore dei pixel, \dots) usando apposite
unità di elaborazione grafica come i pixel shader. Nel 2006 grazie all'architettura CUDA nella scheda grafica GeForce 8800 GTX
di NVIDIA anche le schede grafiche sono equipaggiate con apposite ALI in modo da poter eseguire aritmetica a singola e doppia
precisione, accesso in lettura e scrittura alla memoria centrale e gestione diretta delle memorie cache come la shared memory.

\subsubsection*{Calcolo ibrido GPU+CPU}
Progettare cluster per il calcolo ad alte prestazioni basato sulla struttura ibrida CPU+GPU è più complesso, ma permette di
rendere molto efficiente in termini di tempo l'esecuzione di molte applicazioni di carattere scientifico, matematico, fisico
o ingegneristico. Infatti la CPU consiste di pochi core ottimizzati per l'elaborazione sequenziale, mentre una GPU ha
un'architettura massicciamente parallela che consiste di migliaia di core molto efficiente progettati per trattare task
multipli simultaneamente. Alla CPU si lascia la parte di codice in cui vengono gestite le risorse hardware e software del
sistema, mentre alla GPU si lascia la parte puramente matematica di analisi dati.

\subsubsection*{Tensor Processing Unit - TPU}
Google ha progettato e realizzato un processore proprietario denominato TPU e dedicato alle architetture delle reti neurali per
l’apprendimento approfondito (Deep Learning Neural Networks). È stato chiamato così perché sfrutta la libreria TensorFlow 
sviluppata da Google per DeepLearning.

La TPU è un ASIC (Application Specific Integrated Circuit), ovvero un processore creato per svolgere specifici compiti in maniera
estremamente ottimizzata. I processori TPU, progettati per l’apprendimento automatico, offrono prestazioni migliori per watt e
numero di transistor rispetto alle CPU e GPU grazie all'alta specificità, a una tolleranza maggiore agli errori computazionali
e a circuiti più semplici.

\subsubsection*{Field Programmable Gate Array - FPGA}
I FPGA sono array di componenti hardware programmabili singolarmente detti Configurable Logic Blocks (CLB) interconnessi tra di
loro. In questo modo si può ottenere implementazioni hardware di algoritmi e reti logiche aggiornabili senza dover però sostenere
gli elevati costi di fabbricazione di un chip. Grazie all'implementazione hardware hanno un elevato speedup.

\newpage


% ___________________________________________________________________________________________________________________________________________________
% /////////////////////////////////////////////////////////////////////////|\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
% ------------------------------------------------------------------- CONCORRENZA -------------------------------------------------------------------
% \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\|/////////////////////////////////////////////////////////////////////////
% ***************************************************************************************************************************************************

% ***************************************************************************************************************************************************
% -------------------------------------------------------------- GESTIONE DEI PROCESSI --------------------------------------------------------------
% ***************************************************************************************************************************************************

\section{Concorrenza}
\subsection{Processi e Thread}
Un processo è un'istanza attiva di un programma che comprende tutte le informazioni necessarie per il suo funzionamento, risiede
quindi in RAM. Il programma è un insieme di codice e strutture eseguibile da un elaboratore ed è passivo. Un programma può avere
più istanze di esecuzione, ovvero più processi.

\subsubsection*{Contesto di un processo o Process Control Block - PCB}
Un processo è composto dal codice con le istruzioni da eseguire e dal contesto di esecuzione (o Process Control Block - PCB).
Il PCB è una struttura dati contenente tutte le informazioni per il sistema operativo per gestire un processo durante
il suo ciclo di vita, è salvato in RAM ed è composto da:
\begin{itemize}
	\item identificatore (PID)
	\item stato del processo
	\item contesto della CPU (registri e program counter)
	\item informazioni sulla memoria
	\begin{itemize}[topsep=0pt]
		\item base e limite della memoria dedicata al processo
		\item tabella delle pagine o dei segmenti
		\item heap (memoria dinamica) e stack (variabili locali e RDA)
		\item initialized e uninitialized data segment
	\end{itemize}
	\item informazioni sulle risorse
	\item informazioni di scheduling
	\item informazioni di comunicazione tra processi
\end{itemize}

\subsubsection*{Multiprogrammazione e ruolo del SO nella gestione dei processi}
La multiprogrammazione consiste nell'avere contemporaneamente più job (o processi) salvati in RAM in modo da poterli alternare
tra loro nel caso in cui uno di essi sia in \say{pausa} mentre attende una risorsa. Il SO si deve occupare di:
\begin{itemize}
	\item[1.] creazione e cancellazione di processi (utente e di sistema)
	\item[2.] sospensione e riattivazione di processi (attraverso scheduling della CPU e swapping)
	\item[3.] fornire meccanismi per la sincronizzazione di processi, la comunicazione fra processi e la gestione del deadlock
	(evitare che processi si blocchino in attesa di risorse)
\end{itemize}

\subsubsection*{Stati di un processo}
\begin{itemize}
	\item \textbf{new}: quando un processo è stato appena avviato
	\item \textbf{ready}: quando ha i dati, ma è in coda di esecuzione
	\item \textbf{running}: quando è in esecuzione
	\item \textbf{waiting}: quando sta aspettando le risorse
	\item \textbf{terminated}: quando ha terminato l'esecuzione
\end{itemize}
Il passaggio di un processo dallo stato di ready a quello di running è gestito dall'algoritmo di scheduler dispatch. Quando un
processo passa da running a ready, il PCB di tale processo viene salvato in RAM per poter essere ripristinato la volta successiva
che torna in esecuzione. Lo stato terminated si verifica per terminazione normale e restituzione del controllo al SO, terminazione
anomala (es. eccezioni, \dots), uso scorretto di risorse o chiamata a istruzioni non valide (trap).

\subsubsection*{Scheduling dei processi pt. 1}
Lo scheduling dei processi è un meccanismo messo in atto per massimizzare l’utilizzo della CPU, che consiste nel passare
rapidamente dall’esecuzione di un processo al successivo, garantendo il time sharing. È svolto dal CPU scheduler (modulo del
sistema operativo) che sfrutta tre code:
\begin{itemize}
	\item[1.] \textbf{job queue}: insieme di tutti i processi presenti nel sistema
	\item[2.] \textbf{ready queue}: insieme dei processi ready, prossimi all'esecuzione, che risiedono in memoria centrale
	\item[3.] \textbf{code dei dispositivi}: insieme dei processi in attesa di un dispositivo di I/O
\end{itemize}

\subsubsection*{Thread}
Un thread (filo) è l'unità base di esecuzione all'interno della CPU. Ogni processo deve essere suddiviso in uno o più thread per
essere eseguito. Per gestirne l'esecuzione ogni thread possiede il proprio identificatore di thread TID e il proprio TCB, simile
al PCB ma specifico per i thread. I thread vengono utilizzati nelle architetture multicore perché permettono il parallelismo e la
concorrenza in quanto è possibile eseguire in parallelo più thread, poiché il sistema può assegnare thread diversi a diverse unità
di calcolo.

Linux impiega thread a livello kernel per la gestione dei dispositivi della memoria e delle interrupt e il thread kthreadd con
pid 2 è genitore di tutti i kernel thread.

Ogni thread condivide codice, dati e risorse con gli altri thread dello stesso processo, ma ha istanze di esecuzione e program
counter distinti, per cui è bene fare molta attenzione nella gestione della memoria condivisa e delle risorse condivise tra i
thread di uno stesso programma.


% ***************************************************************************************************************************************************
% ------------------------------------------------------------ CONCORRENZA E PARALLELISMO -----------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Concorrenza vs Parallelismo}
\subsubsection*{Confronto}
\begin{itemize}
	\item La \textbf{concorrenza} è la capacità di gestire più task (finalizzati a risolvere uno stesso problema) in modo
	apparentemente simultaneo, anche se eseguiti su un solo core. I diversi task vengono interrotti e ripresi, uno alla volta,
	molto velocemente.
	\item Il \textbf{parallelismo} è l’esecuzione effettiva e simultanea di più compiti su più core o processori. Necessita
	quindi di architetture parallele (multicore, multithreading, multiprocessori \dots) per essere eseguito.
\end{itemize}

\subsubsection*{Tipi di parallelismo}
\begin{itemize}
	\item \textbf{data parallelism}: la stessa operazione viene eseguita contemporaneamente sui dati, si partizionano i dati
	sui vari thread in modo che non ci siano conflitti e per accelerarne la computazione
	\item \textbf{task parallelism}: parallelizzare del codice tra thread diversi in modo da avere più processi che possono
	essere eseguiti se uno è in attesa di risorse
\end{itemize}

\subsection{Diagrammi temporale}
\subsubsection*{Diagramma dei tempi di esecuzione}
\begin{center}
	\begin{minipage}{0.59\textwidth}
		Il diagramma dei tempi di esecuzione permette di analizzare l'evoluzione di un processo in funzione del tempo. Siccome il
		tempo di esecuzione di un processo dipende da tantissimi fattori, tale grafico è sempre una approssimazione. Il plateau nel
		primo grafico indica che il programma è in attesa di risorse.
	
		Il grafico lineare, posto in basso, indica il tempo in cui verrà eseguito un processo e tornerà utile nello scheduling dei
		processi nella CPU.
	\end{minipage}
	\begin{minipage}{0.4\textwidth}
		\centering
		\includegraphics[width=0.8\textwidth]{diagramma temporale 1.png}
	
		\vspace{5pt}
		\includegraphics[width=0.8\textwidth]{diagramma temporale 2.png}
	\end{minipage}
\end{center}

\subsubsection*{Grafo di precedenza}
\begin{center}
	\begin{minipage}{0.59\textwidth}
		Il grafo di precedenza serve per analizzare le dipendenze tra i vari moduli o subtask del processo, in modo da capire quali
		possono essere parallelizzate e l'ordine con cui devono essere eseguite. In questo modo si evita il problema delle
		approssimazioni sul tempo di esecuzione variabile.
		
		Il tempo di esecuzione complessivo viene calcolato sommando i tempi dei processi in serie e sommando il massimo tra
		processi in parallelo.
	\end{minipage}
	\begin{minipage}{0.4\textwidth}
		\centering
		\includegraphics[width=0.8\textwidth]{diagramma precedenze.png}
	\end{minipage}
\end{center}

\subsubsection*{Sistemi di processi}
Un sistema di processi è un insieme di processi che si definisce:
\begin{itemize}
	\item \textbf{closed system}: se esiste un processo iniziale e uno finale
	\item \textbf{open system}: se non esiste un processo iniziale o uno finale, ma è possibile trasformarlo in chiuso
	introducendo  un processo iniziale e finale dummy
\end{itemize}

\subsubsection*{Massimo grado di parallelismo}
Il massimo grado di parallelismo si intende la cardinalità del più grande sottoinsieme di processi tali per cui, presi due
qualsiasi nodi del sottoinsieme, non esiste un percorso orientato che li connette. Ovvero sono il massimo numero di processi
che verranno eseguri in parallelo (che si trovano allineati verticalmente). In base all'architettura si può voler  minimizzare
il parallelismo per ottimizzare il calcolo in sistemi hardware limitati o massimizzare il parallelismo per massimizzare le
prestazioni.

\subsubsection*{Interferenza e determinatezza}
\begin{itemize}
	\item un sistema di dice \textbf{determinato} se, dati due processi parallelizzati, la velocità e l'ordine di esecuzione non
	influenzano il risultato finale (non ci sono race conditions), altrimenti si dice \textbf{indeterminato}, un esempio di 
	indeterminazione si verifica se entrambi i processi agiscono sulla stessa variabile senza appositi controlli
	\item due processi si dicono \textbf{non interferenti} se uno è il successore dell'altro oppure se non si intersecano i
	codomini e nemmeno i domini con i codomini (ovvero se non vengono eseguiti in parallelo o se agiscono su variabili diverse)
	\item un sistema è determinato se e solo se è costituito da processi non interferenti
	\item due sistemi sono equivalenti se sono determinati, sono costituiti dallo stesso insieme di processi e se dallo stesso
	input producono lo stesso output
\end{itemize}


% ***************************************************************************************************************************************************
% --------------------------------------------------------------------- RISORSE ---------------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Risorse}
La risorsa è un’astrazione per rappresentare una entità necessaria ad un processo per svolgere il proprio lavoro. Può essere sia
output di altro processo (fondamentale per la continuazione del lavoro del processo in esame) che spazio di memoria. Se la risorsa
non è disponibile, il processo ovviamente dovrà attendere per utilizzarla. Dividiamo le risorse:
\begin{itemize}
	\item \textbf{condivisibili}: possono essere usate da più processi in parallelo (es. RAM condivisa)
	\item \textbf{non condivisibili}: non possono essere usate nello stesso tempo (es. stampante)
	\item \textbf{non consumabile}: può essere riutilizzata (es. core di una CPU può essere riutilizzato)
	\item \textbf{consumabile}: non riutilizzabile, in tal caso si parla di risorse esterne al sistema, (es. robot che può ricaricarsi
	da power pack separato dalla rete)
\end{itemize}

\subsubsection*{Prelazione o preemption}
Una risorsa si dice preemptive (o con prelazione) se è possibile sottrarla forzatamente ad un processo in uso per assegnarla ad
un altro processo. Ad esempio se si sottrae il core CPU ad un processo con bassa priorità nel caso in cui ce ne sia un altro con
maggiore priorità.

\subsection{Grafo di assegnazione delle risorse o grafo di Holt}
Il grafo di assegnazione delle risorse è un grafo orientato composto da:
\begin{itemize}
	\item \(T = \{T_1, T_2, \dots\}\) insieme dei thread attivi nel sistema, rappresentato come nodi circolari etichettati con il 
	rispettivo nome
	\item \(R = \{R_1, R_2, \dots\}\) insieme delle risorse presenti nel sistema con le relative istanze \(W_i\), rappresentate da
	rettangoli detti magazzini, con tanti pallini neri quante sono le istanze
	\item \(T_i \to R_j\) arco di richiesta orientato indicante che il thread \(T_i\) ha richiesto la risorsa \(R_j\)
	\item \(R_j \to T_i\) arco di assegnazione orientato indicante che la risorsa \(R_j\) è stata assegnata al thread \(T_i\)
	\item \(T_i \dashrightarrow R_i\) arco di reclamo orientato indicante che \(T_i\) potrebbe richiedere \(R_j\) in futuro
\end{itemize}
Una risorsa \(R_i\) può avere tanti archi uscenti (di assegnazione) quante sono le istante \(W_i\).

\subsubsection*{Costruzione del grafo delle risorse}
Inizialmente si segnano tutte le risorse e tutti i thread e si aggiungono eventuali gli archi di reclamo. Ogni volta che un
thread richiede una risorsa, si converte l'arco di reclamo in arco di richiesta. Se la risorsa è diponibile, l'arco di richiesta
cambia verso e diventa arco di assegnazione. Se la risorsa è già occupata, il richiedente rimane in attesa ed eventualmente viene
messo in una coda FIFO di attesa. Quando una risorsa viene liberata, l'arco di assegnazione torna ad essere un arco di reclamo.

% ***************************************************************************************************************************************************
% --------------------------------------------------------------------- DEADLOCK --------------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Deadlock}
\subsubsection*{Definizione di deadlock}
Un deadlock o stallo indica la situazione per cui si ha un insieme di thread bloccati in quanto ciascuno possiede almento una
risorsa ed attende di acqusirne altre, già allocate da altri thread. Gli stalli possono verificarsi spesso in quanto più thread
possono competere per un numero limitato di risorse. Le sitazioni (necesasarie ma non sufficienti) per cui si può verificare sono:
\begin{itemize}
	\item mutua esclusione delle risorse: una risorsa è utilizzabile solo da un processo contemporaneamente
	\item allocazione parziale: i processi allocano risorse in tempi diversi
	\item risorse senza prelazione: solo il processo che la ha acquisita può rilasciarla
	\item attesa circolare: ogni processo aspetta una risorsa che non verrà rilasciata (problema dei 5 filosofi)
\end{itemize}

\subsubsection*{Definizione di livelock}
Il livelock è una situazione di stallo attivo in cui i thread non sono effettivamente bloccati, ma non progrediscono. In genre
si verifica quando un thread effettua ripetutamente un'azione che non ha successo, ad esempio quando due thread effettuano polling
(busy waiting) per verificare lo stato del'altro reciprocamente (livelock mutuo).

\subsubsection*{Definizione di starvation}
La starvation è una situazione in cui un processo o thread non riesce mai ad ottenere le risorse necessarie per essere eseguito,
rimanendo in attesa (quindi attivo) per un tempo indefinito. Ad esempio quando un processo a bassa priorità non riesce mai ad
essere eseguito data la costante presenza di processi più prioritari.

\subsubsection*{Individuazione dei deadlock dal grafo delle risorse}
Analizzando la presenza di cicli nel grafo delle risorse è possibile stabile l'eventuale presenza di deadlock:
\begin{itemize}
	\item se il grafo non contiene cicli, allora non si hanno deadlock
	\item se il grado contiene cicli e se le risorse coinvolte hanno una singola istanza, allora si ha deadloclk
	\item se il grafo contiene cicli e alcune risorse coinvolte hanno più istanze, potrebbe non esserci deadlock
\end{itemize}

\newpage

\subsubsection*{Algoritmo di individuazione del blocco critico - riduzione del grafo di Holt}
In generale un sistema non è in stallo se e solo se il grafo di Holt è completamente riducibile. Un grafo di Holt è completamente
riducibile se esiste una sequenza di passi di riduzione che elimina tutti gli archi del grafo. Una riduzione è possibile se un
processo può acquisire tutte le risorse che necessita e di conseguenza potrà terminare. Se tutti i processi terminano allora il
sistema non sarà in stallo. Per ridurre il grafo di Holt si ricorre al seguente metodo:
\begin{itemize}
	\item[1.] si scrivono le matrici delle risorse dichiarate \(A\), delle risorse allocate \(B\) e delle risorse richieste \(C\),
	in cui si hanno come colonne le risorse \(R_1, R_2, \dots\) e come prima riga i dati cumulativi del sistema \(S\) e come
	successive i vari processi \(P_1, P_2, \dots\) tali per cui \(A(i,j) = B(i,j) + C(i,j)\)
	\item[2.] si analizza solo la tabella \(C\) e se una certa riga \(P_i\) è minore di \(S\), ovvero se le richieste di \(P_i\)
	possono essere soddisfatte, allora si cancella \(P_i\) e si incrementa la riga \(S\) con le risorse che vengono liberate
	\item[3.] si procede con la cancellazione finché possibile e, se si riescano a cancellare tutte le righe allora il sistema
	non è in deadlock, altrimenti se alcune righe non sono eliminabili si verificherà un deadlock
\end{itemize}

\subsection{Prevenzione del deadlock}
\subsubsection*{Allocazione globale}
L'allocazione globale constiste nel far sì che un processo richieda tutte le risorse di cui ha bisogno in un'unica richiesta,
prima di iniziare l'esecuzione. Se tutte le risorse non sono disponibili, il processo non parte, evitando così situazioni di
attesa circolare.

\subsubsection*{Allocazione gerarchica}
L'allocazione gerarchica si basa sul fatto che tutte le risorse del sistema sono ordinate gerarchicamente, e ogni processo può
richiedere risorse solo seguendo quell’ordine. Ovvero un processo può richiedere solo risorse con numero più alto di quelle che
già possiede. In questo modo non possono verificarsi stalli dovuti al mutuo blocco di risorse (es. \(P_1\) ha \(R_1\) e chiede
\(R_2\), quando \(P_2\) ha \(R_2\) e chiede \(R_1\))

\subsubsection*{Algoritmo del banchiere}
Sfrutta un principio simile al metodo di riduzione del grafo di Holt, quando un processo richiede risorse:
\begin{itemize}
	\item[1.] verifica che le risorse richieste rientrano in quelle dichiarate iniziamente dal processo
	\item[2.] verifica che le risorse richieste siano inferiori di quelle disponibili
	\item[3.] simula l'assegnazione di risorse decrementando quelle disponibili e se ci si trova ancora in uno stato sicuro
	(ovvero se il grafo è riducibile)
	\item[5.] se sì, concede le risorse, altrimenti nega temporaneamente la richiesta
\end{itemize}

\subsubsection*{Ripristino dei deadlock}
Le operazioni per ripristinare uno stato attivo del sistema si chiama recovery e può prevedere:
\begin{itemize}
	\item un rollback, ovvero alcuni processi rilasciano le risorse acquisite per permettere agli altri di proseguire (usato
	specialmente nei database come MySQL dove è possibile il rollback)
	\item la kill dei thread bloccati (secondo una certa priorità) ed eventualmente tutti i sottothread che dipendono da essi
	con possibilità di dover riavviare l'intero sistema, metodo chiamato algoritmo dello struzzo, usato dalla maggior parte dei
	sistemi opearativi
\end{itemize}

\subsubsection*{Gestione dei deadlock}
In genere l'algoritmo del banchiere, sebbene sia ottimo, è molto dispendioso e non viene utilizzato nei sistemi attuali. Vengono
invece impiegati sistemi di:
\begin{itemize}
	\item prevenzione come allocazione gerarchica, alloc. globale, rilascio automatico di risorse (prelazione)
	\item rilevamento con la riduzione del grafo di Holt, eseguito con frequenza variabile in funzione di scelte progettuali
	quali la frequenza stimata di verifica di un deadlock, CPU in stato di sospensione, richieste non soddisfatte
	\item recovery attraverso rollback (se possibile) o applicazione l'algoritmo dello struzzo
\end{itemize}

% ***************************************************************************************************************************************************
% ------------------------------------------------------------------ RACE CONDITION -----------------------------------------------------------------
% ***************************************************************************************************************************************************


\subsection{Race condition e sezioni critiche}
\subsubsection*{Definizione di race condition}
Una race condition indica la situazione in cui due processi parallei e concorrenti modificano contemporaneamente una risorsa
condivisa (es. variabili in memoria) e il risultato dipenderà dall'ordine con cui sono eseguiti.

\subsubsection*{Istruzioni atomiche}
Se più processi modificano le stesse variabili si possono verificare race condition date dal fatto che la modifica fatta da
un programma può essere sovrascritta da quella dall'altro programma. Per evitare questa situazione si utilizzano le istruzioni
atomiche ovvero istruzioni che vengono completate senza subire interruzioni che possono comportare a data race.

Alcune architetture implementano istruzioni atomiche via hardware adn esempio \verb|TestAndSet| per controllare e modificare il
contenuto di una parola in memoria o \verb|CompareAndSwap| per scambiare due parole in memoria.

\subsubsection*{Sezioni critiche}
Se non è possibile completare la computazione utilizzando solo istruzioni atomiche, si utilizzano le sezioni critiche, ovvero
si impongono dei vincoli a determinate regioni del codice affinché si abbia l'esclusività nel tempo della loro esecuzione. Le
sezioni critiche hanno le seguenti proprietà:
\begin{itemize}
	\item mutua esclusione: solo un processo per volta può accedervi
	\item progesso: la scelta del processo che accederà alla regione critica non può essere rimandata all'infinto
	\item attesa limitata: un processo che richiede l'accesso alla sezione critica non può attendere all'infinito
\end{itemize}

\subsubsection*{Sezioni critiche e kernel con/senza prelazione}
In un kernel senza prelazione, i thread del kernel non possono essere interrotti, per cui le race condition su dati del kernel
vengono azzerate (su sistemi single core). Nel caso in cui più processi concorrenti contengano system call, tali system call
verranno gestite individualmente e sequenzialmente.

In un kernel con prelazione, i thread del kernel possono essere interrotti da altri thread e, se non gestiti correttamente, si
può incorrere in race condition. D'altra parte i kernel preemtive sono necessari in sistemi real-time (che devono rispondere a
eventi entro limiti di tempo precisi e garantiti) o nei sistemi time-sharing (in cui si condividono le risorse tra più processi
sfruttando il round robin e i quanti di tempo) siccome si diminuiscono i tempi di risposta.

Il kernel di Windows XP/2000 è (in parte) senza prelazione, ma i sottosistemi di Windows 2000 eseguiti in modalità utente hanno
prelazione. Linux, da 2.6 introduce kernel con diritto di prelazione (sebbene sia personalizzabile attraverso una flag).

\subsubsection*{Implementazione di sezioni critiche}
\begin{itemize}
	\item via hardware: nei sistemi non paralleli è sufficiente impedire che il codice nelle sezioni critiche venga interrotto
	ad esempio bloccando temporaneamente le interrupt
	\item via software: con i lock mutex, semafori e monitor implementati dal kernel
\end{itemize}


% ***************************************************************************************************************************************************
% -------------------------------------------------------------------- LOCK MUTEX -------------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Lock Mutex}
I lock mutex (MUTual EXclusion) sono strumenti software per controllare l'accesso alla regione critica. In entrata di una regione
critica si chiama la funzinne \verb|acquire()| che aspetta in busy waiting finché non è possibile acquisire il flag, mentre in
uscita della regione critica si effettua la \verb|release| in cui si libera il flag acquisito in ingresso. Le due funzioni sono
implementate via hardware, fornite dall'architettura, o sono atomiche per evitare data race.

\begin{lstlisting}[numbers=none]
	acquire() {								|	release() {
		while(!available); /* busy wait */	|		available = true;
		available = false;					|	}
	}										|
\end{lstlisting}


% ***************************************************************************************************************************************************
% --------------------------------------------------------------------- SEMAFORI --------------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Semafori}
\subsubsection*{Semafori contatore}
I semafori contatore hanno un funzionamento simile ai lock mutex, solo che basandosi su un contatore, permettono ad un certo
numero \(s \geq 1\) di processi di entrare in una determinata sezione critica. Per utilizzare un semaforo è necessario prima
dichiararlo, specificandone il valore inziale \(s\). Le operazioni di \verb|acquire| e \verb|release| sono sostituite con
\verb|wait| (che attende che il contatore sia positivo prima di decrementarlo) e \verb|signal| (che reincrementa il contatore),
sempre gestite in maniera atomica.

\begin{lstlisting}[numbers=none]
	semaphore mysem = 2; // dichiarazione di un semaforo con valore s = 2
	--------------------------------------------------------------------------------
	wait(s) {								|	signal(s) {
		while(s <= 0); /* busy wait */		|		s++;
		s--;								|	}
	}										|
\end{lstlisting}
I semafori sono particolarmente utili per gestire le risorse con più di una istanza (es. parcheggi disponibili e occupati in
un parco macchine). Se il contatore può assumere solo i valori \(0\) e \(1\), i semafori associati sono detti semafori binari ed equivalgono a dei
lock mutex.

\subsubsection*{Semafori privati}
I semafori privati sono classici semafori con la caratteristica che solo un processo (proprietario) è abilitato ad eseguirne
la \verb|wait|, mentre qualsiasi processo può eseguirne la \verb|signal|.

\subsubsection*{Come evitare busy waiting}
Si osserva che, per come definito sopra, le istruzioni di \verb|wait| e \verb|signal| sfruttano il busy waiting, spercando
cicli della CPU. È possibile evitare ciò inserendo i processi in attesa in una coda, in modo da risvegliarli ogni volta che
viene fatta una \verb|signal|. In questo caso il contatore può assumere valori negativi e il relativo modulo è il numero di
processi in coda. (negli esercizi si userà l'implementazione precedente)

\begin{lstlisting}[numbers=none]
	typedef struct {
		int value;          // contatore
		struct pcb *list;   // lista con i PCB
	} semaphore;
	--------------------------------------------------------------------------------
	wait(semaphore *s) {
		s->value--;
		if (s-> value < 0)  // se ho terminato le risorse
			block();        // aggiunge il processo a s->list e blocca l'esecuzione
	}
	--------------------------------------------------------------------------------
	signal(semaphore *s) {
		s->value++;
		if (s->value <= 0)  // se ci sono processi sospesi
			wakeup(P);      // risveglia il processo in s->list
	}
\end{lstlisting}

\subsubsection*{Deadlock e starvation}
Il deadlock si verifica se un insieme di processi stanno aspettando un signal che solo uno di loro può fornire, ma che è bloccato.
In genere si verifica quando due programmi acquisiscono due semafori in ordine invertito, per cui uno aspetta che l'altro rilasci
il secondo semaforo e l'altro aspetta che il primo rilasci il primo semaforo.

La starvation si verifica se un processo in coda attende per un tempo indefinito in coda ad un semaforo senza venir mai svegliato.
In genere si verifica se la lista dei processi in attesa è di tipo LIFO, al posto di FIFO, oppure se c'è un diaccopiamento tra
\verb|text| e \verb|text|.

\subsubsection*{Implementazione dei semafori}
\begin{itemize}
	\item \textbf{OpenMP}: API multipiattaforma per la creazione di processi paralleli sia per normali computer che per
	supercomputer, le regioni critiche sfruttano la direttiva \verb|#pragma omp critical { ... }|
	\item \textbf{Intel Threading Building Block - TBB}: libreria in C++ per sviluppare programmi paralleli
\end{itemize}

% ***************************************************************************************************************************************************
% --------------------------------------------------------------------- MONITOR ---------------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Monitor}
\subsubsection*{Condition variables}
Le condition variables sono particolari oggetti in grado di interrompere l'esecuzione di un processo e di risvegliarlo non appena
una determinata condizione è verificata. Di seguito un esempio in C++:

\begin{lstlisting}[numbers=none]
	std::condition_variable my_condition_variable; // dichiarazione
	my_condition_variable.wait(lock, []{ return condizione_logica; }); // wait
	my_condition_variable.notify_one(); // notify_one, conosciuta come signal
	my_condition_variable.notify_all(); // notify_one, conosciuta come broadcast
\end{lstlisting}
\begin{itemize}
	\item \verb|wait|: se la condizione è true, allora non fa nulla, altrimenti mette il processo in \verb|wait| e libera il lock,
	quando riceve una \verb|notify|, la condizione viene riverificata e se rimasta false, allora torna in attesa, altrimenti si
	riprende il lock e continua con il resto dell'esecuzione
	\item \verb|notify_one|: risveglia un processo in attesa, non forzandone la riattivazione in quanto spetta alla \verb|wait| di
	verificare la condizione
	\item \verb|notify_all|: risveglia tutti i processi in attesa (analogo alla \verb|notify_one|)
\end{itemize}

\subsubsection*{Monitor e condition variables}
I monitor sono strumenti alternativi ai semafori che semplificano la gestione della mutua esclusione sacrificando in parte la
parallelizzazione. Grazie all'utilizzo dei mutex, solo un processo per volta può accedere alle loro proceduere. La differenza
principale rispetto ai semafori è che non vegono effettuati nessun incremento o decremento di contatori, ma vengono utilizzate
le condition variable per mettere in attesa e risvegliare i processi. Di seguito un esempio di implementazione di un buffer
utilizzando i monitor in C++:
\begin{lstlisting}
class MonitorBuffer {
private:
	std::queue<int> buffer;   // buffer
	const size_t maxSize = 5; // buffer size
	std::mutex mtx;           // mutex per garantire la mutua esclusivita'
	std::condition_variable notEmpty; // condition variable 1
	std::condition_variable notFull;  // condition variable 1

public:
	void produce(int item) {
		std::unique_lock<std::mutex> lock(mtx); // acquisisce il mutex

		// aspetta finche' non si hanno posti liberi nel buffer
		notFull.wait(lock, [this]() { return buffer.size() < maxSize; });

		buffer.push(item); // inserisce il prodotto
		notEmpty.notify_one(); // sveglia un consumatore
		// mutex rilasciato in automatico ucendo dallo scope grazie a unique_lock
	}

	int consume() {
		std::unique_lock<std::mutex> lock(mtx); // acquisisce il mutex

		// aspetta finche' non si hanno prodotti nel buffer
		notEmpty.wait(lock, [this]() { return !buffer.empty(); });

		int item = buffer.front(); buffer.pop(); // rimuove il prodotto
		notFull.notify_one(); // sveglia un produttore
		return item; // restituisce il prodotto
		// mutex rilasciato in automatico ucendo dallo scope grazie a unique_lock
	}
};
\end{lstlisting}
Si osserva che i processi risegliati dai notity non vengono subito attivati perché devono prima aspettare che i mutex vengano
liberati con l'uscita dalle procedure del monitor. Vengono sì svegliati, ma passano all'esecuzione solo dopo che il programma
che li ha chiamati libera il mutex terminando.

\subsubsection*{Problema dei 5 filosofi}
Nel problema dei 5 filosofi si ha in una tavola rotonda in cui sono seduti attorno 5 filosofi intervallati da una forchetta
per un totale di 5 forchette. I filosofi possono pensare o mangiare, per pensare non è richiesta nessuna risorsa, per mangiare
devono aver acquisito entrambe le forchette che hanno accanto. Di seguito un esempio di codice, si nota che non è possible che
si verifichi deadlock perché acquisiscono entrambe le forchette insieme e non c'è l'\textit{acquire-one-and-wait-the-other}. È
comunque possibile che si verifichi starvation se un filosofo non riesce mai a mangiare.
\begin{lstlisting}
#include <iostream>, <thread>, <mutex>, <condition_variable>, <array>

enum State { THINKING, HUNGRY, EATING }; // stati dei filosofi

class DiningPhilosophers { // e' monitor
private:
	std::mutex mtx;                              // mutex per accesso monitor
	std::array<State, 5> state;                  // stato dei filosofi
    std::array<std::condition_variable, 5> cond; // condition variables

	// funzioni di utilita'
	int left(int i) { return (i + 4) % 5; }
    int right(int i) { return (i + 1) % 5; }

	// se i filosofi a destra e a sinistra non stanno mangiando, cambia stato al
	// filosofo in centro ed effettua una signal su tale filosofo, altrimenti non
	// fa nulla e il thread rimane a dormire
	void test(int i) {
        if (state[i] == HUNGRY && state[left(i)] != EATING && state[right(i)] != EATING){
            state[i] = EATING;  cond[i].notify_one();
        }
    }

public:
	DiningPhilosophers() { state.fill(THINKING); } // inizializzazione con costruttore

	void pickup(int i) {
		std::unique_lock<std::mutex> lock(mtx); // mutex bloccato
		state[i] = HUNGRY; // imposta filosofo su affamato
		test(i); // verifica disponibilita' immediata delle risorse, se libere le prende
		cond.wait(lock, [this, i] { return state[i] == EATING;); // attesa di risorse
	}

	void release(int i) {
        std::unique_lock<std::mutex> lock(mtx); // mutex bloccato
        state[i] = THINKING; // cambia stato del filosofo sazio
        test(left(i));  // signal su quello di sinistra
        test(right(i)); // signal su quello di destra
	}
}

// funzione che esegue ciascun filosofo per pensare, prendere, mangiare e liberare
void philosopher(int i, DiningPhilosophers &D) { 
    auto think = [&](){ std::cout << "Philosopher " << i << " thinking\n"; };
    auto eat = [&](){ std::cout << "Philosopher " << i << " eating\n"; };

    for (int iter = 0; iter < 10; iter++) { // ciclo effettivo
        think();  D.pickup(i);  eat();  D.release(i);
    }
}

// main che fa partire i thread dei vari filosofi
int main() {
    DiningPhilosophers D;             // monitor dei 5 filosofi
    std::vector<std::thread> threads; // thread per ogni filosofo
    for (int i = 0; i < 5; ++i)       // lancia i thread
        threads.emplace_back(philosopher, i, std::ref(D));
    for (auto &t : threads)           // aspetta la fine di tutti i thread
		t.join();
    return 0;
}
\end{lstlisting}

\subsubsection*{Allocazione risorse con tempo massimo di utilizzo}
Si vuole creare un monitor che gestisca l'assegnazione di risorse a singola istanza tra più processi tenendo conto di un tempo
massimo di utilizzo. Di seguito un esempio in pseudocodice dalle slides:

\begin{lstlisting}
class ResourceAllocator {
	condition_variable x; // condition variable
	boolean busy; // flag per capire se risorsa e' gia' utilizzata

	void acquire(int time) { // acquisisce la risorsa
		if (busy) x.wait(time) // aspetta per un tempo pari a time
		busy = TRUE; // la acquisisce indipendentemente dal
	}

	void release() { // libera la risorsa
		busy = FALSE;
		x.signal();
	}

	void initilisazion_code() { // codice di inizializzazione del monito
		busy = FALSE;
	}
}
\end{lstlisting}

Si osservano alcune criticità:
\begin{itemize}
	\item sono gli utilizzatori che devono preoccuparsi di chiamare release dopo il tempo massimo impostato, altrimenti la
	risorsa verrà assegnata contemporaneamente a qualcun altro
	\item il codice non gestisce eventiali false wakeup della condition variable
\end{itemize}

\subsubsection*{Altri esempi visti nelle slides}
Mailbox e parcheggio macchine \dots

% ***************************************************************************************************************************************************
% --------------------------------------------------------------- CONCORRENZA IN LINUX --------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Parallelismo e concorrenza in Linux}
Prima di Linux 2.6, il kernel non aveva prelazione per cui per creare delle sezioni critiche venivano disabilitati gli interrupt
per un breve periodo di tempo. Poi è stata introdotta la prelazione in kernel mode e nella API POSIX sono stati definiti alcuni
strumenti per la gestione della concorrenza (interi atomici, spinlock, mutex, semafori, condition variables e rilevamento deadlock).

\subsubsection*{Interi atomici}
Strumenti per agire con operazioni atomiche su interi (ad esempio sui contatori)
\begin{itemize}
	\item \verb|atomic_t counter| dichiarazione della variabile intera atomica \verb|counter|
	\item \verb|atomic_set(&counter,5)| \(\leftrightarrow\) \verb|counter = 5;|
	\item \verb|atomic_add(10, &counter)| \(\leftrightarrow\) \verb|counter += 10;|
	\item \verb|atomic_sub(4, &counter)| \(\leftrightarrow\) \verb|counter -= 5;|
	\item \verb|atomic_inc(&counter)| \(\leftrightarrow\) \verb|counter++;|
	\item \verb|atomic_read(&counter)| lettura atomica della variabile intera atomica \verb|counter|
\end{itemize}

\subsubsection*{Lock mutex}
Consiste in una variabile booleana che viene gestita attraverso le chiamate a sistema \verb|mutex_lock()| e \verb|mutex_unlock()|.
In C/C++ i mutex sono gestiti con:
\begin{itemize}
	\item \verb|pthread_mutex_t mtx|: dichiarazione del mutex \verb|mtx|
	\item \verb|pthread_mutex_init(&mtx,NULL)|: inizializzazione del mutex
	\item \verb|pthread_mutex_lock(&mtx)|: esegue il lock (eventualmente attendendo) del mutex \verb|mtx|
	\item \verb|pthread_mutex_unlock(&mtx)|: esegue l'unlock del mutex \verb|mtx|
\end{itemize}

\subsubsection*{Spinlock}
Gli spinlock sono mutex che effettano busy waiting mentre sono in attesa di catturare il lock. Sono preferiti ai mutex quando la
sezione critica è estremamente breve, oppure in presenza di sistemi che devono gestire I/O (driver dei dispositivi, o Interrupt
Service Routine (ISR)). Nei sistemi single core sono estremamente sconsigliati perché rubano cicli di clock alla funzione che
attendono che finisca.

\subsubsection*{Semafori in user mode}
Esistono due tipi di semafori in Linux: i semafori con nome (utilizzabili anche da processi non legati tra loro) e semafori senza
nome (condivisi solo tra processi imparentati).
\begin{itemize}
	\item \verb|sem_t sem|: dichiarazione del semaforo senza normalmente \verb|sem|
	\item \verb|sem_init(&sem,int pshared,int value)|: inizializzazione del semaforo
	\item \verb|sem_wait(&sem)|: esegue il wait sul semaforo \verb|sem|
	\item \verb|sem_post(&sem)|: esegue il signal del semaforo \verb|sem|
	\item \verb|sem_destroy(&sem)|: elimina il semaforo \verb|sem| liberando le risorse
	\item \verb|sem_t *sem = sem_open("/mysem", O_CREAT, 0644, 1);| creazione di un semaforo con nome che avrà le sue operazioni
	che noi non approfondiamo
\end{itemize}
Esistono dei semafori utilizzabili nel kernel, solo che ad oggi si preferiscono i mutex o gli spinlock

\subsubsection*{Condition variables}
Le condition variables sono associate ai lock mutex:
\begin{itemize}
	\item \verb|pthread_cond_t cond_var|: dichiarazione della condition variable \verb|cond_var|
	\item \verb|pthread_cond_init(&cond_var,NULL)|: inizializzazione della contition variable
	\item \verb|pthread_cond_wait(&cond_var, &mtx)|: esegue il wait di \verb|cond_var| rilaciando il mutex \verb|mtx|
	\item \verb|pthread_cond_signal(&cond_var)|: esegue la signal della \verb|cond_var|
\end{itemize}
Di solito si esegue la \verb|pthread_cond_wait(&cond_var, &mtx)| all'interno di un ciclo \verb|while| con la condizione da
verificare per il risveglio in quanto la condizione potrebbe non essere verificata oppure potrebbero verificarsi false wakeup.

\subsubsection*{Deadlock detection}
Per tracciare tutte le assegnazioni di risorse e rilevare i deadlock si utilizza \verb|lockdep|. Siccome l'esecuzione del kernel
con \verb|lockdep| attivo è molto rallentata, si utilizza solo in fase di debug.

% ***************************************************************************************************************************************************
% ------------------------------------------------------------------ MEMORY BARRIER -----------------------------------------------------------------
% ***************************************************************************************************************************************************

\subsection{Memory Barrier}
Le memory barrier sono strumenti che forzano l'esecuzione delle store e delle lock richieste dal programma, prima di eseguire
le istruzioni successive. Serve quindi per forzare l'ordinamento delle letture e scritture in memoria. È possibile utilizzarle
sia attraverso primitive hardware che primitive software. In genere si utilizzano in processi concorrenti lock-free con le
ottimizzazioni del compilatore attive: in alcuni casi i compilatori invertono l'ordine delle load e store, con la MB è possibile
forzare l'ordine stabilito per evitare data race.

\newpage


% ___________________________________________________________________________________________________________________________________________________
% /////////////////////////////////////////////////////////////////////////|\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
% ------------------------------------------------------------------ SCHEDULING CPU -----------------------------------------------------------------
% \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\|/////////////////////////////////////////////////////////////////////////
% ***************************************************************************************************************************************************

\section{Scheduling CPU}
\newpage


% ___________________________________________________________________________________________________________________________________________________
% /////////////////////////////////////////////////////////////////////////|\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
% ------------------------------------------------------------------- GESTIONE RAM ------------------------------------------------------------------
% \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\|/////////////////////////////////////////////////////////////////////////
% ***************************************************************************************************************************************************

\section{Gestione memoria principale}
\newpage


% ___________________________________________________________________________________________________________________________________________________
% /////////////////////////////////////////////////////////////////////////|\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
% ------------------------------------------------------------------ GESTIONE FILE ------------------------------------------------------------------
% \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\|/////////////////////////////////////////////////////////////////////////
% ***************************************************************************************************************************************************

\section{Gestione file}
\newpage

% ___________________________________________________________________________________________________________________________________________________
% /////////////////////////////////////////////////////////////////////////|\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
% ------------------------------------------------------------------- AFFIDABILITÀ ------------------------------------------------------------------
% \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\|/////////////////////////////////////////////////////////////////////////
% ***************************************************************************************************************************************************

\section{Affidabilità}

\end{document}